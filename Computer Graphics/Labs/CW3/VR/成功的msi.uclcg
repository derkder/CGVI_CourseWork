// filename: cw3_student.uclcg
// tabGroup: Coursework
// thumbnail: cw3_thumb.png
// displayname: Coursework 3 - 2023/2024
// shortDescription: Coursework 3 - Path Tracing
// author: None
// isHidden: false

function setup()
{
	UI = {};
	UI.tabs = [];
	UI.titleLong = 'Path Tracer';
	UI.titleShort = 'PathTracer';
	UI.numFrames = 10;
	UI.maxFPS = 24;
	UI.renderWidth = 256;
	UI.renderHeight = 128;

	UI.tabs.push(
		{
		visible: true,
		type: `x-shader/x-fragment`,
		title: `Raytracing`,
		id: `TraceFS`,
		initialValue: `#define SOLUTION_LIGHT
#define SOLUTION_BOUNCE
#define SOLUTION_THROUGHPUT
//#define SOLUTION_AA
//#define SOLUTION_MB
//#define SOLUTION_VR_NEE
//#define SOLUTION_VR_GOODSAMPLE
//#define SOLUTION_VR_IMPORTANCES_cos
//#define SOLUTION_VR_IMPORTANCES_brdf
//#define SOLUTION_VR_IMPORTANCES_msi
//#define TEST_RANDOM_DIRECTION


precision highp float;

#define M_PI 3.14159265359

struct Material {
	#ifdef SOLUTION_LIGHT
	vec3 emission;
	/* 
	what gamma is doing in our case
	Gamma correction is applied to control the luminance of the image. 
	In your case, gamma correction ensures that the light emitted from the sources is displayed correctly in terms of intensity and color, 
	enhancing the realism of the path-traced scene.
	*/
	#endif
	vec3 diffuse;
	vec3 specular;
	float glossiness;
};

struct Sphere {
	vec3 position;
#ifdef SOLUTION_MB
#endif
	float radius;
	Material material;
};

struct Plane {
	vec3 normal;
	float d;
	Material material;
};

const int sphereCount = 4;
const int planeCount = 4;
const int emittingSphereCount = 2;
#ifdef SOLUTION_BOUNCE
const int maxPathLength = 2;
#else
const int maxPathLength = 1;
#endif 

struct Scene {
	Sphere[sphereCount] spheres;
	Plane[planeCount] planes;
};

struct Ray {
	vec3 origin;
	vec3 direction;
};

// Contains all information pertaining to a ray/object intersection
struct HitInfo {
	bool hit;
	float t;
	vec3 position;
	vec3 normal;
	Material material;
};

// Contains info to sample a direction and this directions probability
struct DirectionSample {
	vec3 direction;
	float probability;
};

HitInfo getEmptyHit() {
	Material emptyMaterial;
	#ifdef SOLUTION_LIGHT
	emptyMaterial.emission = vec3(0.0);
	#endif
	emptyMaterial.diffuse = vec3(0.0);
	emptyMaterial.specular = vec3(0.0);
	emptyMaterial.glossiness = 1.0;
	return HitInfo(false, 0.0, vec3(0.0), vec3(0.0), emptyMaterial);
}

// Sorts the two t values such that t1 is smaller than t2
void sortT(inout float t1, inout float t2) {
	// Make t1 the smaller t
	if(t2 < t1)  {
		float temp = t1;
		t1 = t2;
		t2 = temp;
	}
}

// Tests if t is in an interval
bool isTInInterval(const float t, const float tMin, const float tMax) {
	return t > tMin && t < tMax;
}

// Get the smallest t in an interval
bool getSmallestTInInterval(float t0, float t1, const float tMin, const float tMax, inout float smallestTInInterval) {

	sortT(t0, t1);

	// As t0 is smaller, test this first
	if(isTInInterval(t0, tMin, tMax)) {
		smallestTInInterval = t0;
		return true;
	}

	// If t0 was not in the interval, still t1 could be
	if(isTInInterval(t1, tMin, tMax)) {
		smallestTInInterval = t1;
		return true;
	}

	// None was
	return false;
}

// Converts a random integer in 15 bits to a float in (0, 1)
float randomIntegerToRandomFloat(int i) {
	return float(i) / 32768.0;
}

// Returns a random integer for every pixel and dimension that remains the same in all iterations
int pixelIntegerSeed(const int dimensionIndex) {
	vec3 p = vec3(gl_FragCoord.xy, dimensionIndex);
	vec3 r = vec3(23.14069263277926, 2.665144142690225,7.358926345 );
	return int(32768.0 * fract(cos(dot(p,r)) * 123456.0));
}

// Returns a random float for every pixel that remains the same in all iterations
float pixelSeed(const int dimensionIndex) {
	return randomIntegerToRandomFloat(pixelIntegerSeed(dimensionIndex));
}

// The global random seed of this iteration
// It will be set to a new random value in each step
uniform int globalSeed;
int randomSeed;
void initRandomSequence() {
	randomSeed = globalSeed + pixelIntegerSeed(0);
}

// Computes integer  x modulo y not available in most WEBGL SL implementations
int mod(const int x, const int y) {
	return int(float(x) - floor(float(x) / float(y)) * float(y));
}

// Returns the next integer in a pseudo-random sequence
int rand() {
	randomSeed = randomSeed * 1103515245 + 12345;
	return mod(randomSeed / 65536, 32768);
}

float uniformRandomImproved(vec2 co){
    float a = 12.9898;
    float b = 78.233;
    float c = 43758.5453;
    float dt= dot(co.xy ,vec2(a,b));
    float sn= mod(dt,3.14);
    return fract(sin(sn) * c);
}

// Returns the next float in this pixels pseudo-random sequence
float uniformRandom() {
	return randomIntegerToRandomFloat(rand());
}

// This is the index of the sample controlled by the framework.
// It increments by one in every call of this shader
uniform int baseSampleIndex;

// Returns a well-distributed number in (0,1) for the dimension dimensionIndex
float sample(const int dimensionIndex) {
	// combining 2 PRNGs to avoid the patterns in the C-standard LCG
	return uniformRandomImproved(vec2(uniformRandom(), uniformRandom()));
}

// This is a helper function to sample two-dimensionaly in dimension dimensionIndex
vec2 sample2(const int dimensionIndex) {
	return vec2(sample(dimensionIndex + 0), sample(dimensionIndex + 1));
}

vec3 sample3(const int dimensionIndex) {
	return vec3(sample(dimensionIndex + 0), sample(dimensionIndex + 1), sample(dimensionIndex + 2));
}

// This is a register of all dimensions that we will want to sample.
// Thanks to Iliyan Georgiev from Solid Angle for explaining proper housekeeping of sample dimensions in ranomdized Quasi-Monte Carlo
//
// There are infinitely many path sampling dimensions.
// These start at PATH_SAMPLE_DIMENSION.
// The 2D sample pair for vertex i is at PATH_SAMPLE_DIMENSION + PATH_SAMPLE_DIMENSION_MULTIPLIER * i + 0
#define ANTI_ALIAS_SAMPLE_DIMENSION 0
#define TIME_SAMPLE_DIMENSION 1
#define PATH_SAMPLE_DIMENSION 3

// This is 2 for two dimensions and 2 as we use it for two purposese: NEE and path connection
#define PATH_SAMPLE_DIMENSION_MULTIPLIER (2 * 2)

vec3 getEmission(const Material material, const vec3 normal) {
	#ifdef SOLUTION_LIGHT
	return material.emission;
	#else 
	// This is wrong. It just returns the diffuse color so that you see something to be sure it is working.
	return material.diffuse;
	#endif
}

vec3 getReflectance(const Material material, const vec3 normal, const vec3 inDirection, const vec3 outDirection) {
	#ifdef SOLUTION_THROUGHPUT
	//vec3 h = normalize(inDirection + outDirection);
	//float cosTheta = max(dot(normal, h), 0.0);
	vec3 r = reflect(inDirection, normal);
	float cosTheta = max(dot(normal, r), 0.0);
	vec3 specular = material.specular * pow(cosTheta, material.glossiness);
	vec3 diffuse = material.diffuse / M_PI;
	return (diffuse + specular * ((material.glossiness + 2.0) / (2.0 * M_PI)));
	#else
	return vec3(1.0);
	#endif
}

vec3 getGeometricTerm(const Material material, const vec3 normal, const vec3 inDirection, const vec3 outDirection) {
	#ifdef SOLUTION_THROUGHPUT
	
	float cosTheta = max(dot(normal, outDirection), 0.0);
	//cosTheta = dot(normal, inDirection);
   return vec3(cosTheta);
	//return vec3(1.); // Perfect reflection for now
	#else
	return vec3(1.0);
	#endif
}

vec3 sphericalToEuclidean(float theta, float phi) {
	float x = sin(theta) * cos(phi);
	float y = sin(theta) * sin(phi);
	float z = cos(theta);
	return vec3(x, y, z);	
}

vec3 getRandomDirection(const int dimensionIndex) {
	#ifdef SOLUTION_BOUNCE
	// Spherical Coordinates Calculation
	vec2 sampleCoords = sample2(PATH_SAMPLE_DIMENSION + 2 * dimensionIndex);
	float theta = acos(2.0 * sampleCoords.x - 1.0);
	float phi = sampleCoords.y * 2.0 * M_PI;

	//Conversion to Cartesian Coordinates
	float x = sin(theta) * cos(phi);
	float y = sin(theta) * sin(phi);
	float z = cos(theta);

	return vec3(x, y, z);
	#else
	// Put your code to compute a random direction in 3D in the #ifdef above
	return vec3(0);
	#endif
}

#ifdef TEST_RANDOM_DIRECTION
// Function to transform random samples to spherical coordinates (theta, phi)
vec2 toSphericalCoordinates(float xi0, float xi1) {
    float theta = acos(2.0 * xi0 - 1.0);
    float phi = xi1 * 2.0 * M_PI;
    return vec2(theta, phi);
}

// Function to convert spherical coordinates to Cartesian coordinates
vec3 toCartesianCoordinates(float theta, float phi) {
    float x = sin(theta) * cos(phi);
    float y = sin(theta) * sin(phi);
    float z = cos(theta);
    return vec3(x, y, z);
}

// Function to check if a vector is a unit vector
bool isUnitVector(vec3 v) {
    const float epsilon = 0.0001;
    return abs(length(v) - 1.0) < epsilon;
}

void testRandomDirection() {
    for (int i = 0; i < 100; i++) {
		int r = rand();
		vec2 sampleCoords = sample2(PATH_SAMPLE_DIMENSION + 2 * r);
		vec2 sc = toSphericalCoordinates(sampleCoords.x, sampleCoords.y);
		vec3 cc = toCartesianCoordinates(sc.x, sc.y);
		if (!isUnitVector(cc)) {
			// Handle the error case
		}
    }
}
#endif

HitInfo intersectSphere(const Ray ray, Sphere sphere, const float tMin, const float tMax) {

#ifdef SOLUTION_MB
#endif
	
	vec3 to_sphere = ray.origin - sphere.position;

	float a = dot(ray.direction, ray.direction);
	float b = 2.0 * dot(ray.direction, to_sphere);
	float c = dot(to_sphere, to_sphere) - sphere.radius * sphere.radius;
	float D = b * b - 4.0 * a * c;
	if (D > 0.0)
	{
		float t0 = (-b - sqrt(D)) / (2.0 * a);
		float t1 = (-b + sqrt(D)) / (2.0 * a);

		float smallestTInInterval;
		if(!getSmallestTInInterval(t0, t1, tMin, tMax, smallestTInInterval)) {
			return getEmptyHit();
		}

		vec3 hitPosition = ray.origin + smallestTInInterval * ray.direction;

		vec3 normal =
			length(ray.origin - sphere.position) < sphere.radius + 0.001?
			-normalize(hitPosition - sphere.position) :
		normalize(hitPosition - sphere.position);

		return HitInfo(
			true,
			smallestTInInterval,
			hitPosition,
			normal,
			sphere.material);
	}
	return getEmptyHit();
}

HitInfo intersectPlane(Ray ray, Plane plane) {
	float t = -(dot(ray.origin, plane.normal) + plane.d) / dot(ray.direction, plane.normal);
	vec3 hitPosition = ray.origin + t * ray.direction;
	return HitInfo(
		true,
		t,
		hitPosition,
		normalize(plane.normal),
		plane.material);
	return getEmptyHit();
}

float lengthSquared(const vec3 x) {
	return dot(x, x);
}

HitInfo intersectScene(Scene scene, Ray ray, const float tMin, const float tMax)
{
	HitInfo best_hit_info;
	best_hit_info.t = tMax;
	best_hit_info.hit = false;

	for (int i = 0; i < sphereCount; ++i) {
		Sphere sphere = scene.spheres[i];
		HitInfo hit_info = intersectSphere(ray, sphere, tMin, tMax);

		if(	hit_info.hit &&
		   hit_info.t < best_hit_info.t &&
		   hit_info.t > tMin)
		{
			best_hit_info = hit_info;
		}
	}

	for (int i = 0; i < planeCount; ++i) {
		Plane plane = scene.planes[i];
		HitInfo hit_info = intersectPlane(ray, plane);

		if(	hit_info.hit &&
		   hit_info.t < best_hit_info.t &&
		   hit_info.t > tMin)
		{
			best_hit_info = hit_info;
		}
	}

	return best_hit_info;
}

mat3 transpose(mat3 m) {
	return mat3(
		m[0][0], m[1][0], m[2][0],
		m[0][1], m[1][1], m[2][1],
		m[0][2], m[1][2], m[2][2]
	);
}

// This function creates a matrix to transform from global space into a local space oriented around the provided vector.
mat3 makeLocalFrame(const vec3 vector) {
	vec3 up = abs(vector.z) < 0.999 ? vec3(0, 0, 1) : vec3(1, 0, 0);
	vec3 T = normalize(cross(up, vector));
	vec3 B = cross(vector, T);
	return mat3(T, B, vector);
}

float luminance(const vec3 color) {
    return dot(color, vec3(0.2126, 0.7152, 0.0722));
}

#define EPSILON (1e-6)  // for avoiding numeric issues caused by floating point accuracy

#ifdef SOLUTION_VR_NEE
vec3 estimateDirectIllumination(const Scene scene, const HitInfo hitInfo, const int lightIndex) {
    // 从场景中选择一个光源
	Sphere light;
	if (lightIndex == 0) {
    	light = scene.spheres[0];
	} else{
    	light = scene.spheres[1];
	}
    // 计算从交点到光源中心的方向和距离
    vec3 direction = light.position - hitInfo.position;
    float distance = length(direction);
    direction = normalize(direction);
	
	  Ray shadowRay;
    shadowRay.origin = hitInfo.position + EPSILON * direction;
    shadowRay.direction = direction;
	  HitInfo shadowHit = intersectScene(scene, shadowRay, EPSILON, distance);
	
    // 发送阴影射线
	//不加下面的判断条件，感觉Variance是减少的
    if (!shadowHit.hit) {
		//这里的逻辑到后面也只有几个像素点进去了
      // 如果直接可见光源，则计算直接光照贡献
      float NdotL = max(dot(hitInfo.normal, direction), 0.0);
      vec3 directIllumination = light.material.emission * NdotL;
      return directIllumination;
    } else {
      return vec3(0.0);
    }
}
#endif

DirectionSample sampleDirection(const vec3 normal, const vec3 inDirection, const vec3 diffuse, const vec3 specular, const float glossiness, const float n, const int dimensionIndex) {
	DirectionSample result;
	vec2 sample = sample2(PATH_SAMPLE_DIMENSION + 2 * dimensionIndex);
	#ifdef SOLUTION_VR_IMPORTANCES_brdf
    // Cook-Torrance BRDF重要性采样
	 DirectionSample result_brdf;
	 float alpha = pow(1.0 - glossiness, 2.0);	
    // 使用GGX/Trowbridge-Reitz法线分布进行重要性采样
    float theta_h = atan(sqrt(-alpha*alpha * log(1.0 - sample.x)));
    float phi_h = 2.0 * M_PI * sample.y;
    
    // 转换到欧几里得空间
    vec3 wm = sphericalToEuclidean(theta_h, phi_h);
    mat3 localFrame = makeLocalFrame(normal);
    vec3 wm_local = localFrame * wm;

    // 转换到世界空间
    vec3 h_world = normalize(localFrame * wm);
    // 计算反射向量
    vec3 wo_local = normalize(reflect(-inDirection, h_world));

    // 计算概率密度函数
    float D = alpha * alpha / (M_PI * pow(cos(theta_h), 4.) * pow(alpha*alpha + tan(theta_h)*tan(theta_h), 2.));
    float pdf = D * cos(theta_h) / (4. * dot(inDirection, h_world));

    result_brdf.direction = wo_local;
    result_brdf.probability = pdf;
	  result = result_brdf;
	#endif
	#ifdef SOLUTION_VR_IMPORTANCES_cos
	//https://zhuanlan.zhihu.com/p/360420413
	DirectionSample result_cos;
    //float theta = acos(sqrt(1. - sample.x));
	float theta = acos(sqrt(2. * sample.x - 1.));
    float phi = 2.0 * M_PI * sample.y;
    vec3 wm2 = sphericalToEuclidean(theta, phi);
    mat3 localFrame2 = makeLocalFrame(normal); // 使用法线创建局部坐标系
    vec3 wm_local2 = localFrame2 * wm2; // 将采样方向转换到局部坐标系
    result_cos.direction = wm_local2;
    result_cos.probability = cos(theta) * sin(theta) / M_PI;
	 result = result_cos;
	#else
	#ifdef SOLUTION_VR_IMPORTANCES_msi
	float weight_brdf = result_brdf.probability / (result_brdf.probability + result_cos.probability);
	float weight_cos = result_cos.probability / (result_brdf.probability + result_cos.probability);

	result.direction = normalize(result.direction_brdf * result.weight_brdf + result.direction_cos * weight_cos);
	result.probability = result.probability_brdf * result.weight_brdf + result.probability_cos * weight_cos;	
	# endif
	// Depending on the technique: put your variance reduction code in the #ifdef above 
	result.direction = getRandomDirection(dimensionIndex);	
	result.probability = 1.0 / (4.0 * M_PI);
	#endif
	return result;
}

vec3 samplePath(const Scene scene, const Ray initialRay) {

	// Initial result is black
	vec3 result = vec3(0);

	Ray incomingRay = initialRay;
	vec3 throughput = vec3(1.0);
	for(int i = 0; i < maxPathLength; i++) {
		HitInfo hitInfo = intersectScene(scene, incomingRay, 0.001, 10000.0);

		if(!hitInfo.hit) return result;
		
		result += throughput * getEmission(hitInfo.material, hitInfo.normal);
		#ifdef SOLUTION_VR_NEE
        // NEE 仅当击中的不是光源时计算
        if (hitInfo.material.emission == vec3(0.0)) {
            // 对每个光源计算直接光照贡献
            for (int lightIdx = 0; lightIdx < emittingSphereCount; ++lightIdx) {
                vec3 directIllumination = estimateDirectIllumination(scene, hitInfo, lightIdx);
                // 如果直接光照有效，则累加到结果中
                if (directIllumination != vec3(0.0)) {
                    result += throughput * directIllumination;
                }
            }
        }
     #endif

		Ray outgoingRay;
		DirectionSample directionSample;
		#ifdef SOLUTION_BOUNCE
		#ifdef TEST_RANDOM_DIRECTION
		testRandomDirection();
		#endif
		
     directionSample = sampleDirection(hitInfo.normal, incomingRay.direction, hitInfo.material.diffuse, hitInfo.material.specular, hitInfo.material.glossiness, 0., i);
	  outgoingRay = Ray(hitInfo.position + EPSILON * directionSample.direction, directionSample.direction);
		#else
			// Put your code to compute the next ray in the #ifdef above
		#endif
		
		#ifdef SOLUTION_THROUGHPUT
		vec3 reflectance = getReflectance(hitInfo.material, hitInfo.normal, -incomingRay.direction, directionSample.direction);
		vec3 geometricTerm = getGeometricTerm(hitInfo.material, hitInfo.normal, -incomingRay.direction, directionSample.direction);
		throughput *= reflectance * geometricTerm;
		//float cosTheta = max(dot(hitInfo.normal, -incomingRay.direction), 0.0);
      //throughput *= reflectance * cosTheta;
		#else
		// Compute the proper throughput in the #ifdef above 
		throughput *= 0.1;
		#endif

		// div by probability of sampled direction 
		throughput /= directionSample.probability; 
	
		#ifdef SOLUTION_BOUNCE
		incomingRay = outgoingRay;
		#else
		// Put some handling of the next and the current ray in the #ifdef above
		#endif
	}
	return result;
}

uniform ivec2 resolution;
Ray getFragCoordRay(const vec2 fragCoord) {

	float sensorDistance = 1.0;
	vec3 origin = vec3(0, 0, sensorDistance);
	vec2 sensorMin = vec2(-1, -0.5);
	vec2 sensorMax = vec2(1, 0.5);
	vec2 pixelSize = (sensorMax - sensorMin) / vec2(resolution);
	vec3 direction = normalize(vec3(sensorMin + pixelSize * fragCoord, -sensorDistance));

	float apertureSize = 0.0;
	float focalPlane = 100.0;
	vec3 sensorPosition = origin + focalPlane * direction;
	origin.xy += -vec2(0.5);
	direction = normalize(sensorPosition - origin);

	return Ray(origin, direction);
}

vec3 colorForFragment(const Scene scene, const vec2 fragCoord) {
	initRandomSequence();
	#ifdef SOLUTION_VR_GOODSAMPLE
	vec3 color = vec3(0.0);
    const int nSamples = 4; // 比如，每个像素4个样本
    float invNSamples = 1.0 / float(nSamples);
    for (int i = 0; i < nSamples; ++i) {
        for (int j = 0; j < nSamples; ++j) {
            // 计算分层采样位置
            float offsetX = (float(i) + uniformRandom()) * invNSamples;
            float offsetY = (float(j) + uniformRandom()) * invNSamples;
            vec2 sampleCoord = fragCoord + vec2(offsetX, offsetY);
            color += samplePath(scene, getFragCoordRay(sampleCoord));
        }
    }
    color *= invNSamples * invNSamples; // 对所有样本取平均
    return color;
	#endif
	
	#ifdef SOLUTION_AA
	// 介于上面initRandomSequence()，这里就要用随机而不是绕一圈
	vec2 sampleCoord_aa = fragCoord;
	vec3 color_aa = vec3(0.0, 0.0, 0.0);
	const int sampleCount_aa = 4; // 比如使用4个样本进行超采样
	for(int i = 0; i < sampleCount_aa; ++i) {
		// 在像素内部生成随机的样本坐标
		float xOffset = uniformRandom() - 0.5;
		float yOffset = uniformRandom() - 0.5;
		sampleCoord_aa = fragCoord + vec2(xOffset, yOffset);      
      // 累加通过场景采样得到的颜色值
      color_aa += samplePath(scene, getFragCoordRay(sampleCoord_aa));
		// 累加通过场景采样得到的颜色值
		color_aa += samplePath(scene, getFragCoordRay(sampleCoord_aa));
	}
	// 对所有样本的颜色值求平均
	color_aa /= float(sampleCount_aa);
	return color_aa;
	#else  	
	// Put your anti-aliasing code in the #ifdef above
	vec2 sampleCoord = fragCoord;
	return samplePath(scene, getFragCoordRay(sampleCoord));
	#endif
}

void loadScene1(inout Scene scene) {

	scene.spheres[0].position = vec3(7, -2, -12);
	scene.spheres[0].radius = 2.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[0].material.emission = 15. * vec3(0.9, 0.9, 0.5);
#endif
	scene.spheres[0].material.diffuse = vec3(0.5);
	scene.spheres[0].material.specular = vec3(0.5);
	scene.spheres[0].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
#endif
	
	scene.spheres[1].position = vec3(-8, 4, -13);
	scene.spheres[1].radius = 1.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[1].material.emission = 15. * vec3(0.8, 0.3, 0.1);
#endif
	scene.spheres[1].material.diffuse = vec3(0.5);
	scene.spheres[1].material.specular = vec3(0.5);
	scene.spheres[1].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
#endif
	
	scene.spheres[2].position = vec3(-2, -2, -12);
	scene.spheres[2].radius = 3.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[2].material.emission = vec3(0.);
#endif  
	scene.spheres[2].material.diffuse = vec3(0.2, 0.5, 0.8);
	scene.spheres[2].material.specular = vec3(0.8);
	scene.spheres[2].material.glossiness = 40.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
#endif
	
	scene.spheres[3].position = vec3(3, -3.5, -14);
	scene.spheres[3].radius = 1.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[3].material.emission = vec3(0.);
#endif  
	scene.spheres[3].material.diffuse = vec3(0.9, 0.8, 0.8);
	scene.spheres[3].material.specular = vec3(1.0);
	scene.spheres[3].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
#endif
	
	scene.planes[0].normal = vec3(0, 1, 0);
	scene.planes[0].d = 4.5;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[0].material.emission = vec3(0.);
#endif
	scene.planes[0].material.diffuse = vec3(0.8);
	scene.planes[0].material.specular = vec3(0.0);
	scene.planes[0].material.glossiness = 50.0;    

	scene.planes[1].normal = vec3(0, 0, 1);
	scene.planes[1].d = 18.5;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[1].material.emission = vec3(0.);
#endif
	scene.planes[1].material.diffuse = vec3(0.9, 0.6, 0.3);
	scene.planes[1].material.specular = vec3(0.02);
	scene.planes[1].material.glossiness = 3000.0;

	scene.planes[2].normal = vec3(1, 0,0);
	scene.planes[2].d = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[2].material.emission = vec3(0.);
#endif
	
	scene.planes[2].material.diffuse = vec3(0.2);
	scene.planes[2].material.specular = vec3(0.1);
	scene.planes[2].material.glossiness = 100.0; 

	scene.planes[3].normal = vec3(-1, 0,0);
	scene.planes[3].d = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[3].material.emission = vec3(0.);
#endif
	
	scene.planes[3].material.diffuse = vec3(0.2);
	scene.planes[3].material.specular = vec3(0.1);
	scene.planes[3].material.glossiness = 100.0; 
}


void main() {
	// Setup scene
	Scene scene;
	loadScene1(scene);

	// compute color for fragment
	gl_FragColor.rgb = colorForFragment(scene, gl_FragCoord.xy);
	gl_FragColor.a = 1.0;
}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	UI.tabs.push(
		{
		visible: true,
		type: `x-shader/x-fragment`,
		title: `Tonemapping`,
		id: `CopyFS`,
		initialValue: `precision highp float;

uniform sampler2D radianceTexture;
uniform int sampleCount;
uniform ivec2 resolution;

vec3 tonemap(vec3 color, float maxLuminance, float gamma) {
	float luminance = length(color);
	//float scale =  luminance /  maxLuminance;
	float scale =  luminance / (maxLuminance * luminance + 0.0000001);
  	return max(vec3(0.0), pow(scale * color, vec3(1.0 / gamma)));
}

void main(void) {
  vec3 texel = texture2D(radianceTexture, gl_FragCoord.xy / vec2(resolution)).rgb;
  vec3 radiance = texel / float(sampleCount);
  gl_FragColor.rgb = tonemap(radiance, 1.0, 1.6);
  gl_FragColor.a = 1.0;
}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	UI.tabs.push(
		{
		visible: false,
		type: `x-shader/x-vertex`,
		title: ``,
		id: `VS`,
		initialValue: `
	attribute vec3 position;
	void main(void) {
		gl_Position = vec4(position, 1.0);
	}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	 return UI; 
}//!setup


function getShader(gl, id) {

		gl.getExtension('OES_texture_float');
		//alert(gl.getSupportedExtensions());

	var shaderScript = document.getElementById(id);
	if (!shaderScript) {
		return null;
	}

	var str = "";
	var k = shaderScript.firstChild;
	while (k) {
		if (k.nodeType == 3) {
			str += k.textContent;
		}
		k = k.nextSibling;
	}

	var shader;
	if (shaderScript.type == "x-shader/x-fragment") {
		shader = gl.createShader(gl.FRAGMENT_SHADER);
	} else if (shaderScript.type == "x-shader/x-vertex") {
		shader = gl.createShader(gl.VERTEX_SHADER);
	} else {
		return null;
	}

    console.log(str);
	gl.shaderSource(shader, str);
	gl.compileShader(shader);

	if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
		alert(gl.getShaderInfoLog(shader));
		return null;
	}

	return shader;
}

function RaytracingDemo() {
}

function initShaders() {

	traceProgram = gl.createProgram();
	gl.attachShader(traceProgram, getShader(gl, "VS"));
	gl.attachShader(traceProgram, getShader(gl, "TraceFS"));
	gl.linkProgram(traceProgram);
	gl.useProgram(traceProgram);
	traceProgram.vertexPositionAttribute = gl.getAttribLocation(traceProgram, "position");
	gl.enableVertexAttribArray(traceProgram.vertexPositionAttribute);

	copyProgram = gl.createProgram();
	gl.attachShader(copyProgram, getShader(gl, "VS"));
	gl.attachShader(copyProgram, getShader(gl, "CopyFS"));
	gl.linkProgram(copyProgram);
	gl.useProgram(copyProgram);
	traceProgram.vertexPositionAttribute = gl.getAttribLocation(copyProgram, "position");
	gl.enableVertexAttribArray(copyProgram.vertexPositionAttribute);

}

function initBuffers() {
	triangleVertexPositionBuffer = gl.createBuffer();
	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);

	var vertices = [
		 -1,  -1,  0,
		 -1,  1,  0,
		 1,  1,  0,

		 -1,  -1,  0,
		 1,  -1,  0,
		 1,  1,  0,
	 ];
	gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW);
	triangleVertexPositionBuffer.itemSize = 3;
	triangleVertexPositionBuffer.numItems = 3 * 2;
}


function tick() {

// 1st pass: Trace
	gl.bindFramebuffer(gl.FRAMEBUFFER, rttFramebuffer);

	gl.useProgram(traceProgram);
  	gl.uniform1i(gl.getUniformLocation(traceProgram, "globalSeed"), Math.random() * 32768.0);
	gl.uniform1i(gl.getUniformLocation(traceProgram, "baseSampleIndex"), getCurrentFrame());
	gl.uniform2i(
		gl.getUniformLocation(traceProgram, "resolution"),
		getRenderTargetWidth(),
		getRenderTargetHeight());

	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);
	gl.vertexAttribPointer(
		traceProgram.vertexPositionAttribute,
		triangleVertexPositionBuffer.itemSize,
		gl.FLOAT,
		false,
		0,
		0);

    	gl.viewport(0, 0, gl.viewportWidth, gl.viewportHeight);

	gl.disable(gl.DEPTH_TEST);
	gl.enable(gl.BLEND);
	gl.blendFunc(gl.ONE, gl.ONE);

	gl.drawArrays(gl.TRIANGLES, 0, triangleVertexPositionBuffer.numItems);

// 2nd pass: Average
   	gl.bindFramebuffer(gl.FRAMEBUFFER, null);

	gl.useProgram(copyProgram);
	gl.uniform1i(gl.getUniformLocation(copyProgram, "sampleCount"), getCurrentFrame() + 1);

	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);
	gl.vertexAttribPointer(
		copyProgram.vertexPositionAttribute,
		triangleVertexPositionBuffer.itemSize,
		gl.FLOAT,
		false,
		0,
		0);

    	gl.viewport(0, 0, gl.viewportWidth, gl.viewportHeight);

	gl.disable(gl.DEPTH_TEST);
	gl.disable(gl.BLEND);

	gl.activeTexture(gl.TEXTURE0);
    	gl.bindTexture(gl.TEXTURE_2D, rttTexture);
	gl.uniform1i(gl.getUniformLocation(copyProgram, "radianceTexture"), 0);
	gl.uniform2i(
		gl.getUniformLocation(copyProgram, "resolution"),
		getRenderTargetWidth(),
		getRenderTargetHeight());

	gl.drawArrays(gl.TRIANGLES, 0, triangleVertexPositionBuffer.numItems);

	gl.bindTexture(gl.TEXTURE_2D, null);
}

function init() {
	initShaders();
	initBuffers();
	gl.clear(gl.COLOR_BUFFER_BIT);

	rttFramebuffer = gl.createFramebuffer();
	gl.bindFramebuffer(gl.FRAMEBUFFER, rttFramebuffer);

	rttTexture = gl.createTexture();
	gl.bindTexture(gl.TEXTURE_2D, rttTexture);
    	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);

	gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, getRenderTargetWidth(), getRenderTargetHeight(), 0, gl.RGBA, gl.FLOAT, null);

	gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, rttTexture, 0);
}

var oldWidth = 0;
var oldTraceProgram;
var oldCopyProgram;
function compute(canvas) {

	if(	getRenderTargetWidth() != oldWidth ||
		oldTraceProgram != document.getElementById("TraceFS") ||
		oldCopyProgram !=  document.getElementById("CopyFS"))
	{
		init();

		oldWidth = getRenderTargetWidth();
		oldTraceProgram = document.getElementById("TraceFS");
		oldCopyProgram = document.getElementById("CopyFS");
	}

	tick();
}
