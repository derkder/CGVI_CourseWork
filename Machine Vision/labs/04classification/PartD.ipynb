{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Part D: Face detection with logistic regression\n",
    "The goal of this part of the practical is to implement logistic regression for classifying faces and non-faces. \n",
    "\n",
    "**TO DO:** This is a complete working bit of code. Your goals are to:\n",
    "1. Look at the code and understand it\n",
    "2. Investigate what happens as you increase the amount of training data - try 750, 1000, 1500, 2000, 3000, 4000 examples.  Does it generalize better?\n",
    "3. Try learning with gradient descent with 4000 examples. What happens?\n",
    "4. Convert this to a non-linear logistic regression algorithm by transforming the data before running the routine (see the '`transform`' method of the '`LogisticRegression`' class). Write a routine to transform each data point to a 500x1  vector by evaluating it against 500 radial basis functions.  \n",
    "\n",
    "    The centers of these functions can be the first 500 data points.  You should experiment with the standard deviation, but somewhere in the range 1-100 should be a good start.\n",
    "    \n",
    "    **Note:** since this non-linear model will be largely the same as the linear version, you may want to create a sub-class that inherits from '`LogisticRegression`', and only overrides the '`transform`' method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "from functions import LogisticRegressionNLL\n",
    "from optimisation import SteepestDescent, NewtonMethod, optimise\n",
    "from utils import add_bias, visualise_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, filename):\n",
    "        self.data = loadmat(filename)\n",
    "        self.training_images = self.data['x'].transpose(2, 0, 1).astype(np.float32) / 256\n",
    "        self.training_labels = self.data['y'].squeeze()\n",
    "        self.testing_images = self.data['xTest'].transpose(2, 0, 1).astype(np.float32) / 256\n",
    "        self.testing_labels = self.data['yTest'].squeeze()\n",
    "\n",
    "    def training(self, num_examples=None):\n",
    "        return self.training_images[slice(num_examples)], self.training_labels[slice(num_examples)]\n",
    "\n",
    "    def testing(self, num_examples=None):\n",
    "        return self.testing_images[slice(num_examples)], self.testing_labels[slice(num_examples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, dimensions):\n",
    "        self.phi = add_bias(1e-4 * np.random.randn(dimensions, 1))\n",
    "\n",
    "    def transform(self, image):\n",
    "        return add_bias(image.flatten())\n",
    "\n",
    "    def __call__(self, images):\n",
    "        x = np.stack([self.transform(image) for image in images], axis=1)\n",
    "        return sigmoid(self.phi.T @ x)\n",
    "\n",
    "    def train(self, data, max_iterations, optimiser, tolerance=1e-8):\n",
    "        images, labels = data\n",
    "        x = np.stack([self.transform(image) for image in images], axis=1)\n",
    "        phi_opt, _ = optimise(self.phi, tolerance, function=LogisticRegressionNLL(x, labels),\n",
    "                              optimiser=optimiser, max_iterations=max_iterations)\n",
    "        self.phi = phi_opt[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "data = DataLoader('FaceDetectData.mat')\n",
    "\n",
    "visualise_faces(data.training())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "We define the model we are fitting to be logistic regression for 576-dimensional data, i.e. flattened vectors of the 24x24 pixel images. The model is trained using a subset of the training data, and its parameters are updated internally. You can see in the [previous section](#Define-logistic-regression-model) where we defined the model how this is implemented, and verify that it is just an abstraction of what we did in Parts B and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(dimensions=24*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train(data.training(num_examples=600), max_iterations=50, optimiser=NewtonMethod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and evaluation\n",
    "Now that it has been trained, calling the model as a function on images will output the probability of that image being a face or a non-face. This is compared against the ground truth labels for accuracy, and can be visually verified also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model(data.training_images) > 0.5\n",
    "correct_prediction = prediction == data.training_labels\n",
    "print('Training Data: Classified {:3.3f}% correct'.format(100 * correct_prediction.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prediction = model(data.testing_images) > 0.5\n",
    "correct_prediction = prediction == data.testing_labels\n",
    "print('Test Data: Classified {:3.3f}% correct'.format(100 * correct_prediction.mean()))\n",
    "\n",
    "visualise_faces((data.testing_images, prediction.squeeze()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}